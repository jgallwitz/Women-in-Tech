# -*- coding: utf-8 -*-
"""WIT_PCA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TDhX2JMC_DdXQyHfwdnXYlJmqFyRRoti
"""

# import necessary libraries
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# read in CSV file and view dataset
jobs_survey = pd.read_csv('/content/job_survey.csv')
jobs_survey.head()

# dropping all rows that are outside of the US
jobs_survey = jobs_survey.drop(jobs_survey[jobs_survey['Country'] != 'United States of America'].index)

# dropping all NonDev employees
jobs_survey = jobs_survey.drop(jobs_survey[jobs_survey['MainBranch'] != 'Dev'].index)

# drop all nonbinary respondents since I want to compare men and women
jobs_survey = jobs_survey.drop(jobs_survey[jobs_survey['Gender'] == 'NonBinary'].index)

# reindexing
jobs_survey = jobs_survey.reset_index(drop=True)

# drop specified columns
jobs_survey = jobs_survey.drop(columns = ['Unnamed: 0', 'Accessibility','HaveWorkedWith'])

# view dataset
jobs_survey.head()

# drop qualitative columns as they are not conducive to performing PCA
jobs_survey_PCA = jobs_survey.drop(columns = ['Age', 'EdLevel','Employment','Employed','MentalHealth','MainBranch','Country'])
jobs_survey_PCA.head()

# convert jobs_survey_PCA to CSV
jobs_survey_PCA.to_csv('jobs_survey_PCA.csv', index=False)

# import libraries for PCA
import numpy as np
from sklearn.decomposition import PCA
from sklearn.preprocessing import scale
from sklearn.preprocessing import StandardScaler

# define features to be used for PCA and scale them using StandardScaler
features = jobs_survey_PCA[['YearsCode', 'YearsCodePro', 'PreviousSalary', 'ComputerSkills']]
scaled_features = StandardScaler().fit_transform(features)

# print scaled features
scaled_features

# perform PCA on scaled features using sklearn package
pca = PCA()
principalComponents = pca.fit_transform(scaled_features)

# create a df with principal components
principalDf = pd.DataFrame(data = principalComponents)

principalDf = pd.DataFrame(data = principalComponents
                           , columns = ['principal component 1', 'principal component 2', 'principal component 3', 'principal component 4'])

# add back in Gender label to be used for plotting purposes
finalDf = pd.concat([principalDf, jobs_survey_PCA[['Gender']]], axis = 1)

# calculate and print explained variance
explained_variance = pca.explained_variance_ratio_
explained_variance

# print cumulative explained variance to ensure accuracy
pca.explained_variance_ratio_.cumsum()

# create and print df of cumulative variance
cumulative_variance = np.cumsum(explained_variance)

cumulative_variance_df = pd.DataFrame({
    'Principal Component': [f'PC{i+1}' for i in range(len(cumulative_variance))],
    'Cumulative Variance': cumulative_variance
})

cumulative_variance_df.round(4)

# plot principal components 1 & 2, coloring by Gender
fig = plt.figure(figsize = (8,8))
ax = fig.add_subplot(1,1,1)
ax.set_xlabel('Principal Component 1', fontsize = 15)
ax.set_ylabel('Principal Component 2', fontsize = 15)
ax.set_title('2 component PCA', fontsize = 20)

targetsName = ['Woman', 'Man']

targets = ['Woman', 'Man']
colors = ['r', 'b']
for target, color in zip(targets,colors):
    indicesToKeep = finalDf['Gender'] == target
    ax.scatter(finalDf.loc[indicesToKeep, 'principal component 1']
               , finalDf.loc[indicesToKeep, 'principal component 2']
               , c = color
               , s = 50
               , alpha = 0.1)
ax.legend(targetsName)
ax.grid()

# plot principal components 1, 2, & 3, coloring by Gender
fig = plt.figure(figsize = (8,8))
ax = fig.add_subplot(1,1,1,  projection='3d')
ax.set_xlabel('Principal Component 1', fontsize = 15)
ax.set_ylabel('Principal Component 2', fontsize = 15)
ax.set_zlabel('Principal Component 3', fontsize = 15, labelpad=0.000001)
ax.set_title('3 component PCA', fontsize = 20)

targetsName = ['Woman', 'Man']

targets = ['Woman', 'Man']
colors = ['r', 'b']
for target, color in zip(targets,colors):
    indicesToKeep = finalDf['Gender'] == target
    ax.scatter(  finalDf.loc[indicesToKeep, 'principal component 1']
               , finalDf.loc[indicesToKeep, 'principal component 2']
               , finalDf.loc[indicesToKeep, 'principal component 3']
               , c = color
               , s = 50
                 , alpha = 0.1)
ax.legend(targetsName)
ax.grid()

# calculate and print top 3 eigenvalues
eigenvalues = pca.explained_variance_

top_three_eigenvalues = eigenvalues[:3]

top_three_eigenvalues